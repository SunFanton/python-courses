{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6782c56c",
   "metadata": {},
   "source": [
    "# K-Vecinos Más Cercanos (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a4e02",
   "metadata": {},
   "source": [
    "Texto extraído de `ChatGPT`:\n",
    "\n",
    "El **algoritmo de k vecinos más cercanos (k-NN, por sus siglas en inglés)** es un algoritmo de **aprendizaje supervisado** utilizado tanto para **clasificación** como para **regresión**. Es uno de los algoritmos más simples y fáciles de entender en el campo del aprendizaje automático. La idea básica detrás del algoritmo es que un dato se clasifica o se predice en función de los \"k\" ejemplos más cercanos en el espacio de características.\n",
    "\n",
    "## ¿Cómo funciona el algoritmo de k-NN?\n",
    "\n",
    "1. **Definir el número de vecinos (k)**: Se selecciona el valor de \"k\", que indica cuántos vecinos más cercanos se considerarán para hacer la predicción. \"k\" debe ser un número entero positivo.\n",
    "   \n",
    "2. **Calcular la distancia entre los puntos**: Se mide la **distancia** entre el nuevo punto de datos y todos los puntos de datos en el conjunto de entrenamiento. Las distancias más comunes son:\n",
    "   - **Distancia Euclidiana**: La más utilizada, especialmente en problemas de clasificación y regresión.\n",
    "   - **Distancia de Manhattan**: Suma de las diferencias absolutas entre las coordenadas.\n",
    "   - **Distancia de Minkowski**: Generalización de la distancia Euclidiana y Manhattan.\n",
    "\n",
    "3. **Identificar los k vecinos más cercanos**: Una vez que se han calculado las distancias, se seleccionan los \"k\" puntos de datos más cercanos al nuevo punto que se desea clasificar o predecir.\n",
    "\n",
    "4. **Clasificación o Predicción**:\n",
    "   - **Clasificación**: Para un problema de clasificación, se asigna la etiqueta de clase más frecuente entre los k vecinos más cercanos. En caso de empate, se puede usar un criterio adicional, como la clase de menor distancia media.\n",
    "   - **Regresión**: Para un problema de regresión, la predicción será el valor promedio de las etiquetas de los k vecinos más cercanos.\n",
    "\n",
    "## Ejemplo de clasificación con k-NN:\n",
    "Imagina que tienes un conjunto de datos con dos características (por ejemplo, altura y peso) y clases de frutas (manzana y naranja). Si deseas clasificar un nuevo punto (por ejemplo, con altura 160 cm y peso 80 kg), el algoritmo de k-NN calculará la distancia entre este punto y todos los puntos en el conjunto de entrenamiento, seleccionará los k vecinos más cercanos (por ejemplo, k=3) y asignará la clase mayoritaria entre esos tres vecinos (por ejemplo, 2 manzanas y 1 naranja, por lo que clasificaría la fruta como manzana).\n",
    "\n",
    "## Características principales del algoritmo k-NN:\n",
    "\n",
    "- **No paramétrico**: No realiza suposiciones sobre la distribución de los datos. Es decir, no requiere un modelo previo.\n",
    "- **Instancia basada**: Al ser un algoritmo basado en instancias, no construye un modelo explícito, sino que guarda todos los datos de entrenamiento.\n",
    "- **Curse of Dimensionality (Maleficio de la Dimensionalidad)**: El rendimiento de k-NN puede verse afectado negativamente cuando los datos tienen muchas características (dimensiones). A medida que la cantidad de dimensiones aumenta, las distancias entre los puntos se vuelven más similares, lo que hace que el algoritmo sea menos efectivo.\n",
    "\n",
    "## Ventajas del algoritmo k-NN:\n",
    "1. **Simplicidad**: Es fácil de entender e implementar.\n",
    "2. **Eficiencia en entrenamiento**: No requiere un proceso de entrenamiento real, ya que el modelo simplemente memoriza el conjunto de entrenamiento.\n",
    "3. **Adaptabilidad**: Se adapta bien a cambios en los datos, ya que no necesita un proceso de ajuste o entrenamiento largo.\n",
    "\n",
    "## Desventajas del algoritmo k-NN:\n",
    "1. **Computacionalmente costoso**: Durante la predicción, el algoritmo debe calcular la distancia de cada punto de prueba con todos los puntos de entrenamiento, lo cual puede ser muy lento en conjuntos de datos grandes.\n",
    "2. **Dependencia de la elección de k**: La precisión del algoritmo depende mucho de la elección del valor de \"k\". Si \"k\" es demasiado pequeño, el modelo puede ser sensible a ruido (overfitting), y si es demasiado grande, puede ser demasiado general (underfitting).\n",
    "3. **Sensibilidad a la escala de las características**: Si las características tienen diferentes escalas (por ejemplo, altura en cm y peso en kg), la distancia entre los puntos puede no ser significativa. En este caso, es recomendable normalizar o estandarizar las características.\n",
    "\n",
    "## Elección del parámetro \"k\":\n",
    "\n",
    "- Si \"k\" es pequeño (por ejemplo, 1), el modelo será muy sensible a puntos atípicos (overfitting).\n",
    "- Si \"k\" es grande, el modelo se vuelve más general y puede ignorar detalles importantes (underfitting).\n",
    "- En la práctica, se elige \"k\" mediante validación cruzada, probando varios valores y seleccionando el que ofrezca mejor rendimiento.\n",
    "\n",
    "## Conclusión:\n",
    "\n",
    "El algoritmo **k-NN** es una herramienta simple pero poderosa para tareas de clasificación y regresión. Aunque puede no ser el más eficiente para grandes volúmenes de datos o alta dimensionalidad, sigue siendo muy popular debido a su facilidad de implementación y su rendimiento en muchos problemas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f24b4c1",
   "metadata": {},
   "source": [
    "## Ejemplo en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f6acd",
   "metadata": {},
   "source": [
    "### Datos de clientes bancarios: crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a95a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47861174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>credito</th>\n",
       "      <th>cumplio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>363112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>477965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>239072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>195265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>482174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edad  credito  cumplio\n",
       "0    18   363112        0\n",
       "1    19   477965        1\n",
       "2    20   239072        0\n",
       "3    22   195265        0\n",
       "4    22   482174        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientes = pd.read_csv(\"../datos/creditos.csv\")\n",
    "clientes.head() # cumplio (con pago del credito) -> 0: no, 1: sí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53890f3e",
   "metadata": {},
   "source": [
    "### Pagadores VS Deudores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da099b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167, 3), (33, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buenos = clientes[clientes[\"cumplio\"] == 1]\n",
    "malos = clientes[clientes[\"cumplio\"] == 0]\n",
    "buenos.shape, malos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d012031",
   "metadata": {},
   "source": [
    "### Gráfica: Pagadores VS Deudores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56871260",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(buenos[\"edad\"], buenos[\"credito\"], \n",
    "            marker=\"*\", \n",
    "            s=150, \n",
    "            color=\"skyblue\", \n",
    "            label=\"Sí pagó (Clase: 1)\")\n",
    "\n",
    "plt.scatter(malos[\"edad\"], malos[\"credito\"], \n",
    "            marker=\"*\", \n",
    "            s=150, \n",
    "            color=\"red\", \n",
    "            label=\"No pagó (Clase: 0)\")\n",
    "\n",
    "plt.plot([0,1,2,3],[0,1,2,3])\n",
    "\n",
    "plt.ylabel(\"Monto del crédito\")\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.legend(bbox_to_anchor=(1, 0.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b61edf-e535-40d8-bdae-90b022bc182a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
